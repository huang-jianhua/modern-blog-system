# ç°ä»£åŒ–åšå®¢ç³»ç»Ÿ - éƒ¨ç½²è¿ç»´æŒ‡å—

## ğŸš€ éƒ¨ç½²æ¶æ„

### ç”Ÿäº§ç¯å¢ƒæ¶æ„å›¾
```
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   CDN (é˜¿é‡Œäº‘)   â”‚
                          â”‚  é™æ€èµ„æºåŠ é€Ÿ     â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  Load Balancer  â”‚
                          â”‚   (Nginx)       â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚               â”‚               â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Web Server   â”‚  Web Server   â”‚ Web Server   â”‚
            â”‚  (Node.js)     â”‚  (Node.js)    â”‚ (Node.js)    â”‚
            â”‚   Port: 3001   â”‚  Port: 3002   â”‚ Port: 3003   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚              â”‚              â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   PostgreSQL    â”‚
                          â”‚   ä¸»ä»å¤åˆ¶       â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚               â”‚               â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     Redis     â”‚ Elasticsearch â”‚   ç›‘æ§æœåŠ¡     â”‚
            â”‚     ç¼“å­˜      â”‚    æœç´¢å¼•æ“    â”‚ (Prometheus)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆ

#### Dockerfile - åç«¯æœåŠ¡
```dockerfile
# packages/backend/Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY package*.json ./
COPY packages/backend/package*.json ./packages/backend/
COPY packages/shared/package*.json ./packages/shared/

# å®‰è£…ä¾èµ–
RUN npm ci --only=production

# å¤åˆ¶æºä»£ç 
COPY packages/backend ./packages/backend
COPY packages/shared ./packages/shared

# æ„å»ºåº”ç”¨
WORKDIR /app/packages/backend
RUN npm run build

# ç”Ÿäº§é•œåƒ
FROM node:18-alpine AS runner

RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs

WORKDIR /app

# å¤åˆ¶æ„å»ºç»“æœ
COPY --from=builder --chown=nextjs:nodejs /app/packages/backend/dist ./dist
COPY --from=builder --chown=nextjs:nodejs /app/packages/backend/node_modules ./node_modules
COPY --from=builder --chown=nextjs:nodejs /app/packages/backend/package.json ./package.json

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js

USER nextjs

EXPOSE 3001

ENV NODE_ENV=production

CMD ["node", "dist/server.js"]
```

#### Dockerfile - å‰ç«¯åº”ç”¨
```dockerfile
# packages/frontend/Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY package*.json ./
COPY packages/frontend/package*.json ./packages/frontend/
COPY packages/shared/package*.json ./packages/shared/

# å®‰è£…ä¾èµ–
RUN npm ci

# å¤åˆ¶æºä»£ç 
COPY packages/frontend ./packages/frontend
COPY packages/shared ./packages/shared

# æ„å»ºåº”ç”¨
WORKDIR /app/packages/frontend
RUN npm run build

# Nginx ç”Ÿäº§é•œåƒ
FROM nginx:alpine AS runner

# å¤åˆ¶æ„å»ºç»“æœ
COPY --from=builder /app/packages/frontend/dist /usr/share/nginx/html

# å¤åˆ¶ Nginx é…ç½®
COPY packages/frontend/nginx.conf /etc/nginx/conf.d/default.conf

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost/ || exit 1

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

## ğŸ”„ CI/CD æµæ°´çº¿

### GitHub Actions é…ç½®
```yaml
# .github/workflows/deploy.yml
name: éƒ¨ç½²æµæ°´çº¿

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: æ£€å‡ºä»£ç 
      uses: actions/checkout@v4

    - name: è®¾ç½® Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'

    - name: å®‰è£…ä¾èµ–
      run: npm ci

    - name: è¿è¡Œ ESLint
      run: npm run lint

    - name: è¿è¡Œç±»å‹æ£€æŸ¥
      run: npm run type-check

    - name: è¿è¡Œå•å…ƒæµ‹è¯•
      run: npm run test:unit
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379

    - name: è¿è¡Œé›†æˆæµ‹è¯•
      run: npm run test:integration
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379

    - name: ç”Ÿæˆæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
      run: npm run test:coverage

    - name: ä¸Šä¼ è¦†ç›–ç‡åˆ° Codecov
      uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        service: [frontend, backend]

    steps:
    - name: æ£€å‡ºä»£ç 
      uses: actions/checkout@v4

    - name: è®¾ç½® Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: ç™»å½•åˆ° Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: æå–å…ƒæ•°æ®
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-${{ matrix.service }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha

    - name: æ„å»ºå¹¶æ¨é€ Docker é•œåƒ
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./packages/${{ matrix.service }}/Dockerfile
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  security-scan:
    needs: build
    runs-on: ubuntu-latest
    
    steps:
    - name: æ£€å‡ºä»£ç 
      uses: actions/checkout@v4

    - name: è¿è¡Œ Trivy æ¼æ´æ‰«æ
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-backend:${{ github.sha }}
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: ä¸Šä¼ æ‰«æç»“æœåˆ° GitHub Security
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  deploy-staging:
    needs: [test, build, security-scan]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    
    environment:
      name: staging
      url: https://staging.blog.example.com

    steps:
    - name: éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.STAGING_HOST }}
        username: ${{ secrets.STAGING_USERNAME }}
        key: ${{ secrets.STAGING_SSH_KEY }}
        script: |
          cd /opt/blog-system
          docker-compose -f docker-compose.staging.yml pull
          docker-compose -f docker-compose.staging.yml up -d
          docker system prune -f

    - name: è¿è¡Œå¥åº·æ£€æŸ¥
      run: |
        sleep 30
        curl -f https://staging.blog.example.com/health || exit 1

    - name: è¿è¡Œ E2E æµ‹è¯•
      run: npm run test:e2e
      env:
        BASE_URL: https://staging.blog.example.com

  deploy-production:
    needs: [deploy-staging]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    environment:
      name: production
      url: https://blog.example.com

    steps:
    - name: éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.PRODUCTION_HOST }}
        username: ${{ secrets.PRODUCTION_USERNAME }}
        key: ${{ secrets.PRODUCTION_SSH_KEY }}
        script: |
          cd /opt/blog-system
          
          # å¤‡ä»½å½“å‰ç‰ˆæœ¬
          docker tag ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-backend:latest backup-$(date +%Y%m%d%H%M%S)
          
          # æ‹‰å–æ–°é•œåƒ
          docker-compose -f docker-compose.prod.yml pull
          
          # æ»šåŠ¨æ›´æ–°
          docker-compose -f docker-compose.prod.yml up -d --no-deps backend
          
          # ç­‰å¾…å¥åº·æ£€æŸ¥
          sleep 30
          
          # éªŒè¯æœåŠ¡æ­£å¸¸
          if curl -f http://localhost:3001/health; then
            echo "Backend deployment successful"
            docker-compose -f docker-compose.prod.yml up -d --no-deps frontend
          else
            echo "Backend deployment failed, rolling back"
            docker-compose -f docker-compose.prod.yml rollback
            exit 1
          fi

    - name: é€šçŸ¥éƒ¨ç½²ç»“æœ
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
      if: always()
```

### Kubernetes éƒ¨ç½²é…ç½®
```yaml
# k8s/namespace.yml
apiVersion: v1
kind: Namespace
metadata:
  name: blog-system

---
# k8s/backend-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blog-backend
  namespace: blog-system
spec:
  replicas: 3
  selector:
    matchLabels:
      app: blog-backend
  template:
    metadata:
      labels:
        app: blog-backend
    spec:
      containers:
      - name: backend
        image: ghcr.io/username/blog-system-backend:latest
        ports:
        - containerPort: 3001
        env:
        - name: NODE_ENV
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: blog-secrets
              key: database-url
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: blog-secrets
              key: redis-url
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: blog-secrets
              key: jwt-secret
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3001
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 3001
          initialDelaySeconds: 5
          periodSeconds: 5

---
# k8s/backend-service.yml
apiVersion: v1
kind: Service
metadata:
  name: blog-backend-service
  namespace: blog-system
spec:
  selector:
    app: blog-backend
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3001
  type: ClusterIP

---
# k8s/frontend-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blog-frontend
  namespace: blog-system
spec:
  replicas: 2
  selector:
    matchLabels:
      app: blog-frontend
  template:
    metadata:
      labels:
        app: blog-frontend
    spec:
      containers:
      - name: frontend
        image: ghcr.io/username/blog-system-frontend:latest
        ports:
        - containerPort: 80
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"

---
# k8s/ingress.yml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: blog-ingress
  namespace: blog-system
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  tls:
  - hosts:
    - blog.example.com
    secretName: blog-tls
  rules:
  - host: blog.example.com
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: blog-backend-service
            port:
              number: 80
      - path: /
        pathType: Prefix
        backend:
          service:
            name: blog-frontend-service
            port:
              number: 80
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### Prometheus ç›‘æ§é…ç½®
```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

scrape_configs:
  # åº”ç”¨ç›‘æ§
  - job_name: 'blog-backend'
    static_configs:
      - targets: ['backend:3001']
    metrics_path: '/metrics'
    scrape_interval: 10s

  # ç³»ç»Ÿç›‘æ§
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # æ•°æ®åº“ç›‘æ§
  - job_name: 'postgres-exporter'
    static_configs:
      - targets: ['postgres-exporter:9187']

  # Redis ç›‘æ§
  - job_name: 'redis-exporter'
    static_configs:
      - targets: ['redis-exporter:9121']

  # Nginx ç›‘æ§
  - job_name: 'nginx-exporter'
    static_configs:
      - targets: ['nginx-exporter:9113']

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

### å‘Šè­¦è§„åˆ™é…ç½®
```yaml
# monitoring/alert_rules.yml
groups:
- name: blog-system-alerts
  rules:
  # é«˜é”™è¯¯ç‡å‘Šè­¦
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "é«˜é”™è¯¯ç‡æ£€æµ‹åˆ°"
      description: "{{ $labels.instance }} é”™è¯¯ç‡è¶…è¿‡ 10%"

  # å“åº”æ—¶é—´å‘Šè­¦
  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "å“åº”æ—¶é—´è¿‡é•¿"
      description: "{{ $labels.instance }} 95% å“åº”æ—¶é—´è¶…è¿‡ 1 ç§’"

  # å†…å­˜ä½¿ç”¨å‘Šè­¦
  - alert: HighMemoryUsage
    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.9
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
      description: "{{ $labels.instance }} å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡ 90%"

  # CPU ä½¿ç”¨å‘Šè­¦
  - alert: HighCPUUsage
    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "CPU ä½¿ç”¨ç‡è¿‡é«˜"
      description: "{{ $labels.instance }} CPU ä½¿ç”¨ç‡è¶…è¿‡ 80%"

  # æ•°æ®åº“è¿æ¥å‘Šè­¦
  - alert: DatabaseConnectionFail
    expr: up{job="postgres-exporter"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "æ•°æ®åº“è¿æ¥å¤±è´¥"
      description: "PostgreSQL æ•°æ®åº“è¿æ¥å¤±è´¥"

  # æœåŠ¡å­˜æ´»å‘Šè­¦
  - alert: ServiceDown
    expr: up == 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "æœåŠ¡ä¸å¯ç”¨"
      description: "{{ $labels.instance }} æœåŠ¡å·²åœæ­¢è¿è¡Œ"
```

### æ—¥å¿—èšåˆé…ç½®
```yaml
# logging/fluentd.conf
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# åº”ç”¨æ—¥å¿—
<filter blog.backend.**>
  @type parser
  key_name log
  reserve_data true
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%L%z
  </parse>
</filter>

# é”™è¯¯æ—¥å¿—ç‰¹æ®Šå¤„ç†
<filter blog.backend.**>
  @type grep
  <regexp>
    key level
    pattern ^(error|fatal)$
  </regexp>
  @label @ERROR
</filter>

# è¾“å‡ºåˆ° Elasticsearch
<match blog.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  index_name blog-logs
  type_name _doc
  include_tag_key true
  tag_key @log_name
  <buffer>
    flush_interval 10s
  </buffer>
</match>

# é”™è¯¯æ—¥å¿—å‘Šè­¦
<label @ERROR>
  <match blog.backend.**>
    @type slack
    webhook_url "#{ENV['SLACK_WEBHOOK_URL']}"
    channel "#alerts"
    username "FluentD"
    icon_emoji ":exclamation:"
    title "åº”ç”¨é”™è¯¯å‘Šè­¦"
    message "é”™è¯¯è¯¦æƒ…: %s"
    message_keys log
  </match>
</label>
```

## ğŸ”§ è¿ç»´è„šæœ¬

### éƒ¨ç½²è„šæœ¬
```bash
#!/bin/bash
# scripts/deploy.sh

set -e

ENVIRONMENT=${1:-staging}
VERSION=${2:-latest}

echo "ğŸš€ å¼€å§‹éƒ¨ç½²åˆ° $ENVIRONMENT ç¯å¢ƒï¼Œç‰ˆæœ¬: $VERSION"

# éªŒè¯ç¯å¢ƒ
if [[ "$ENVIRONMENT" != "staging" && "$ENVIRONMENT" != "production" ]]; then
    echo "âŒ æ— æ•ˆçš„ç¯å¢ƒ: $ENVIRONMENT"
    echo "æ”¯æŒçš„ç¯å¢ƒ: staging, production"
    exit 1
fi

# è®¾ç½®ç¯å¢ƒå˜é‡
source config/$ENVIRONMENT.env

# å¤‡ä»½å½“å‰ç‰ˆæœ¬ï¼ˆä»…ç”Ÿäº§ç¯å¢ƒï¼‰
if [[ "$ENVIRONMENT" == "production" ]]; then
    echo "ğŸ“¦ å¤‡ä»½å½“å‰ç‰ˆæœ¬..."
    docker tag $DOCKER_REGISTRY/blog-backend:latest $DOCKER_REGISTRY/blog-backend:backup-$(date +%Y%m%d%H%M%S)
    docker tag $DOCKER_REGISTRY/blog-frontend:latest $DOCKER_REGISTRY/blog-frontend:backup-$(date +%Y%m%d%H%M%S)
fi

# æ‹‰å–æ–°é•œåƒ
echo "ğŸ“¥ æ‹‰å–æœ€æ–°é•œåƒ..."
docker pull $DOCKER_REGISTRY/blog-backend:$VERSION
docker pull $DOCKER_REGISTRY/blog-frontend:$VERSION

# æ›´æ–°æ ‡ç­¾
docker tag $DOCKER_REGISTRY/blog-backend:$VERSION $DOCKER_REGISTRY/blog-backend:latest
docker tag $DOCKER_REGISTRY/blog-frontend:$VERSION $DOCKER_REGISTRY/blog-frontend:latest

# æ•°æ®åº“è¿ç§»
echo "ğŸ—„ï¸ æ‰§è¡Œæ•°æ®åº“è¿ç§»..."
docker run --rm \
  --network blog_network \
  -e DATABASE_URL=$DATABASE_URL \
  $DOCKER_REGISTRY/blog-backend:latest \
  npm run migrate

# æ»šåŠ¨æ›´æ–°åç«¯æœåŠ¡
echo "ğŸ”„ æ›´æ–°åç«¯æœåŠ¡..."
docker-compose -f docker-compose.$ENVIRONMENT.yml up -d --no-deps backend

# å¥åº·æ£€æŸ¥
echo "ğŸ©º åç«¯å¥åº·æ£€æŸ¥..."
for i in {1..30}; do
    if curl -f http://localhost:3001/health > /dev/null 2>&1; then
        echo "âœ… åç«¯æœåŠ¡å¥åº·"
        break
    fi
    if [[ $i -eq 30 ]]; then
        echo "âŒ åç«¯å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œå›æ»š..."
        docker-compose -f docker-compose.$ENVIRONMENT.yml rollback backend
        exit 1
    fi
    sleep 10
done

# æ›´æ–°å‰ç«¯æœåŠ¡
echo "ğŸ”„ æ›´æ–°å‰ç«¯æœåŠ¡..."
docker-compose -f docker-compose.$ENVIRONMENT.yml up -d --no-deps frontend

# æ¸…ç†æ—§é•œåƒ
echo "ğŸ§¹ æ¸…ç†æ—§é•œåƒ..."
docker image prune -f

# å‘é€é€šçŸ¥
echo "ğŸ“¢ å‘é€éƒ¨ç½²é€šçŸ¥..."
curl -X POST $SLACK_WEBHOOK_URL \
  -H 'Content-type: application/json' \
  --data "{\"text\":\"âœ… åšå®¢ç³»ç»Ÿå·²æˆåŠŸéƒ¨ç½²åˆ° $ENVIRONMENT ç¯å¢ƒï¼Œç‰ˆæœ¬: $VERSION\"}"

echo "ğŸ‰ éƒ¨ç½²å®Œæˆï¼"
```

### å¤‡ä»½è„šæœ¬
```bash
#!/bin/bash
# scripts/backup.sh

set -e

BACKUP_DIR="/opt/backups/blog-system"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=7

echo "ğŸ“¦ å¼€å§‹æ•°æ®å¤‡ä»½..."

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# æ•°æ®åº“å¤‡ä»½
echo "ğŸ—„ï¸ å¤‡ä»½æ•°æ®åº“..."
docker exec blog_postgres pg_dump -U blog_user blog_db | gzip > $BACKUP_DIR/database_$DATE.sql.gz

# Redis å¤‡ä»½
echo "ğŸ’¾ å¤‡ä»½ Redis..."
docker exec blog_redis redis-cli --rdb /data/dump.rdb
docker cp blog_redis:/data/dump.rdb $BACKUP_DIR/redis_$DATE.rdb

# æ–‡ä»¶ä¸Šä¼ å¤‡ä»½
echo "ğŸ“ å¤‡ä»½ä¸Šä¼ æ–‡ä»¶..."
tar -czf $BACKUP_DIR/uploads_$DATE.tar.gz /opt/blog-system/uploads

# é…ç½®æ–‡ä»¶å¤‡ä»½
echo "âš™ï¸ å¤‡ä»½é…ç½®æ–‡ä»¶..."
tar -czf $BACKUP_DIR/config_$DATE.tar.gz /opt/blog-system/config

# æ¸…ç†è¿‡æœŸå¤‡ä»½
echo "ğŸ§¹ æ¸…ç†è¿‡æœŸå¤‡ä»½..."
find $BACKUP_DIR -name "*.gz" -mtime +$RETENTION_DAYS -delete
find $BACKUP_DIR -name "*.rdb" -mtime +$RETENTION_DAYS -delete

# ä¸Šä¼ åˆ°äº‘å­˜å‚¨
echo "â˜ï¸ ä¸Šä¼ åˆ°é˜¿é‡Œäº‘ OSS..."
ossutil cp -r $BACKUP_DIR oss://blog-backups/$(date +%Y%m%d)/

echo "âœ… å¤‡ä»½å®Œæˆï¼"
```

### ç›‘æ§è„šæœ¬
```bash
#!/bin/bash
# scripts/health-check.sh

set -e

SERVICES=("frontend" "backend" "postgres" "redis" "elasticsearch")
SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}

echo "ğŸ©º å¼€å§‹å¥åº·æ£€æŸ¥..."

for service in "${SERVICES[@]}"; do
    echo "æ£€æŸ¥ $service æœåŠ¡..."
    
    case $service in
        "frontend")
            if curl -f http://localhost:3000 > /dev/null 2>&1; then
                echo "âœ… $service æ­£å¸¸"
            else
                echo "âŒ $service å¼‚å¸¸"
                send_alert "$service æœåŠ¡ä¸å¯ç”¨"
            fi
            ;;
        "backend")
            if curl -f http://localhost:3001/health > /dev/null 2>&1; then
                echo "âœ… $service æ­£å¸¸"
            else
                echo "âŒ $service å¼‚å¸¸"
                send_alert "$service æœåŠ¡ä¸å¯ç”¨"
            fi
            ;;
        "postgres")
            if docker exec blog_postgres pg_isready -U blog_user > /dev/null 2>&1; then
                echo "âœ… $service æ­£å¸¸"
            else
                echo "âŒ $service å¼‚å¸¸"
                send_alert "$service æ•°æ®åº“è¿æ¥å¤±è´¥"
            fi
            ;;
        "redis")
            if docker exec blog_redis redis-cli ping > /dev/null 2>&1; then
                echo "âœ… $service æ­£å¸¸"
            else
                echo "âŒ $service å¼‚å¸¸"
                send_alert "$service ç¼“å­˜æœåŠ¡å¼‚å¸¸"
            fi
            ;;
        "elasticsearch")
            if curl -f http://localhost:9200/_cluster/health > /dev/null 2>&1; then
                echo "âœ… $service æ­£å¸¸"
            else
                echo "âŒ $service å¼‚å¸¸"
                send_alert "$service æœç´¢å¼•æ“å¼‚å¸¸"
            fi
            ;;
    esac
done

function send_alert() {
    local message=$1
    if [[ -n "$SLACK_WEBHOOK_URL" ]]; then
        curl -X POST $SLACK_WEBHOOK_URL \
          -H 'Content-type: application/json' \
          --data "{\"text\":\"ğŸš¨ å‘Šè­¦: $message\"}"
    fi
}

echo "âœ… å¥åº·æ£€æŸ¥å®Œæˆï¼"
```

## ğŸ“š è¿ç»´æ–‡æ¡£

### æ•…éšœæ’é™¤æŒ‡å—

#### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

**1. æœåŠ¡å¯åŠ¨å¤±è´¥**
```bash
# æ£€æŸ¥æ—¥å¿—
docker-compose logs -f backend

# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tlnp | grep :3001

# é‡å¯æœåŠ¡
docker-compose restart backend
```

**2. æ•°æ®åº“è¿æ¥é—®é¢˜**
```bash
# æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
docker exec blog_postgres pg_isready -U blog_user

# æŸ¥çœ‹è¿æ¥æ•°
docker exec blog_postgres psql -U blog_user -d blog_db -c "SELECT count(*) FROM pg_stat_activity;"

# é‡å¯æ•°æ®åº“
docker-compose restart postgres
```

**3. Redis ç¼“å­˜é—®é¢˜**
```bash
# æ£€æŸ¥ Redis çŠ¶æ€
docker exec blog_redis redis-cli ping

# æŸ¥çœ‹å†…å­˜ä½¿ç”¨
docker exec blog_redis redis-cli info memory

# æ¸…ç©ºç¼“å­˜
docker exec blog_redis redis-cli flushall
```

**4. ç£ç›˜ç©ºé—´ä¸è¶³**
```bash
# æ£€æŸ¥ç£ç›˜ä½¿ç”¨æƒ…å†µ
df -h

# æ¸…ç† Docker èµ„æº
docker system prune -a

# æ¸…ç†æ—¥å¿—æ–‡ä»¶
find /var/log -name "*.log" -mtime +7 -delete
```

### æ€§èƒ½ä¼˜åŒ–æŒ‡å—

#### æ•°æ®åº“ä¼˜åŒ–
```sql
-- åˆ†ææ…¢æŸ¥è¯¢
SELECT query, mean_time, calls 
FROM pg_stat_statements 
ORDER BY mean_time DESC 
LIMIT 10;

-- åˆ›å»ºå¿…è¦ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_posts_published_at 
ON posts (published_at DESC) 
WHERE status = 'published';

-- åˆ†æè¡¨ç»Ÿè®¡ä¿¡æ¯
ANALYZE posts;
```

#### ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
```bash
# ç›‘æ§ç¼“å­˜å‘½ä¸­ç‡
docker exec blog_redis redis-cli info stats | grep keyspace

# è®¾ç½®åˆç†çš„è¿‡æœŸæ—¶é—´
# çƒ­ç‚¹æ•°æ®: 1å°æ—¶
# ç”¨æˆ·ä¼šè¯: 24å°æ—¶
# é™æ€å†…å®¹: 1å‘¨
```

---

## ğŸ¯ è¿ç»´äº¤ä»˜ç‰©

1. **éƒ¨ç½²æ¶æ„å›¾** âœ…
2. **å®¹å™¨åŒ–é…ç½®** âœ…
3. **CI/CD æµæ°´çº¿** âœ…
4. **ç›‘æ§å‘Šè­¦é…ç½®** âœ…
5. **æ—¥å¿—èšåˆæ–¹æ¡ˆ** âœ…
6. **è¿ç»´è„šæœ¬** âœ…
7. **æ•…éšœæ’é™¤æŒ‡å—** âœ…
8. **æ€§èƒ½ä¼˜åŒ–æ–‡æ¡£** âœ…

é€šè¿‡è¿™å¥—å®Œæ•´çš„éƒ¨ç½²è¿ç»´æ–¹æ¡ˆï¼Œåšå®¢ç³»ç»Ÿå·²å…·å¤‡ç”Ÿäº§ç¯å¢ƒçš„é«˜å¯ç”¨æ€§ã€å¯æ‰©å±•æ€§å’Œå¯ç»´æŠ¤æ€§ï¼ğŸš€ 